#!/usr/bin/env node

const puppeteer = require('puppeteer')
const fs = require('fs')
const path = require('path')

// í¬ë¡¤ë§.mdì—ì„œ ìº í˜ì¸ URL ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
function getCampaignUrls() {
  const mdFilePath = path.join(__dirname, '..', 'í¬ë¡¤ë§.md')
  const content = fs.readFileSync(mdFilePath, 'utf8')
  
  const lines = content.split('\n').filter(line => line.trim())
  const campaigns = []
  
  for (let i = 0; i < lines.length; i += 3) {
    if (i + 2 < lines.length) {
      const id = lines[i].trim()
      const title = lines[i + 1].trim()
      const url = lines[i + 2].trim()
      
      if (id && title && url.startsWith('https://')) {
        campaigns.push({
          id: parseInt(id),
          title: title.replace(/^\[|\]$/g, ''),
          url: url
        })
      }
    }
  }
  
  return campaigns
}

// ë‹¨ì¼ ìº í˜ì¸ í¬ë¡¤ë§
async function scrapeCampaign(page, campaign) {
  try {
    console.log(`ğŸ” í¬ë¡¤ë§ ì¤‘: ${campaign.title}`)
    
    await page.goto(campaign.url, { 
      waitUntil: 'networkidle2',
      timeout: 30000 
    })
    
    // í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
    await new Promise(resolve => setTimeout(resolve, 3000))
    
    // ìº í˜ì¸ ì •ë³´ ì¶”ì¶œ
    const campaignData = await page.evaluate(() => {
      const data = {}
      
      // ì œëª©
      const titleEl = document.querySelector('h1, .campaign-title, .title')
      data.title = titleEl ? titleEl.textContent.trim() : ''
      
      // ë¸Œëœë“œ
      const brandEl = document.querySelector('.brand, .company, .brand-name')
      data.brand = brandEl ? brandEl.textContent.trim() : ''
      
      // ì„¤ëª…
      const descEl = document.querySelector('.description, .campaign-desc, .content')
      data.description = descEl ? descEl.textContent.trim() : ''
      
      // ì´ë¯¸ì§€
      const images = []
      const imgElements = document.querySelectorAll('img')
      imgElements.forEach(img => {
        if (img.src && !img.src.includes('logo') && !img.src.includes('icon')) {
          images.push(img.src)
        }
      })
      data.images = images.slice(0, 5) // ìµœëŒ€ 5ê°œ
      
      // ê°€ê²© ì •ë³´
      const priceEl = document.querySelector('.price, .amount, .reward')
      data.price = priceEl ? priceEl.textContent.trim() : ''
      
      // ì¹´í…Œê³ ë¦¬
      const categoryEl = document.querySelector('.category, .tag')
      data.category = categoryEl ? categoryEl.textContent.trim() : ''
      
      // ê¸°ê°„
      const periodEl = document.querySelector('.period, .date, .deadline')
      data.period = periodEl ? periodEl.textContent.trim() : ''
      
      return data
    })
    
    return {
      ...campaign,
      ...campaignData,
      crawledAt: new Date().toISOString(),
      status: 'success'
    }
    
  } catch (error) {
    console.error(`âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: ${campaign.title} - ${error.message}`)
    return {
      ...campaign,
      error: error.message,
      crawledAt: new Date().toISOString(),
      status: 'failed'
    }
  }
}

// ë©”ì¸ í¬ë¡¤ë§ í•¨ìˆ˜
async function crawlAllCampaigns() {
  console.log('ğŸš€ Revu ìº í˜ì¸ í¬ë¡¤ë§ ì‹œì‘...')
  
  const campaigns = getCampaignUrls()
  console.log(`ğŸ“Š ì´ ${campaigns.length}ê°œ ìº í˜ì¸ í¬ë¡¤ë§ ì˜ˆì •`)
  
  let browser
  try {
    browser = await puppeteer.launch({
      headless: true,
      args: [
        '--no-sandbox',
        '--disable-setuid-sandbox',
        '--disable-dev-shm-usage',
        '--disable-web-security',
        '--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
      ]
    })
    
    const page = await browser.newPage()
    
    // ê¸°ë³¸ ì„¤ì •
    await page.setViewport({ width: 1920, height: 1080 })
    await page.setUserAgent('Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36')
    
    const results = []
    
    // ê° ìº í˜ì¸ í¬ë¡¤ë§ (ìˆœì°¨ì ìœ¼ë¡œ)
    for (let i = 0; i < campaigns.length; i++) {
      const campaign = campaigns[i]
      console.log(`\\n[${i + 1}/${campaigns.length}] ì²˜ë¦¬ ì¤‘...`)
      
      const result = await scrapeCampaign(page, campaign)
      results.push(result)
      
      // ìš”ì²­ ê°„ê²© (ì„œë²„ ë¶€í•˜ ë°©ì§€)
      await new Promise(resolve => setTimeout(resolve, 2000))
    }
    
    // ê²°ê³¼ ì €ì¥
    const outputDir = path.join(__dirname, '..', 'crawled-data')
    if (!fs.existsSync(outputDir)) {
      fs.mkdirSync(outputDir, { recursive: true })
    }
    
    // ì „ì²´ ê²°ê³¼ ì €ì¥
    const allDataFile = path.join(outputDir, 'crawled-campaigns.json')
    fs.writeFileSync(allDataFile, JSON.stringify(results, null, 2), 'utf8')
    console.log(`\\nâœ… ì „ì²´ ë°ì´í„° ì €ì¥: ${allDataFile}`)
    
    // ì„±ê³µí•œ ìº í˜ì¸ë§Œ ì €ì¥
    const successResults = results.filter(r => r.status === 'success')
    const successFile = path.join(outputDir, 'successful-campaigns.json')
    fs.writeFileSync(successFile, JSON.stringify(successResults, null, 2), 'utf8')
    console.log(`âœ… ì„±ê³µ ë°ì´í„° ì €ì¥: ${successFile}`)
    
    // ìš”ì•½ ì¶œë ¥
    console.log(`\\nğŸ“‹ í¬ë¡¤ë§ ì™„ë£Œ ìš”ì•½:`)
    console.log(`- ì´ ìº í˜ì¸: ${results.length}ê°œ`)
    console.log(`- ì„±ê³µ: ${successResults.length}ê°œ`)
    console.log(`- ì‹¤íŒ¨: ${results.length - successResults.length}ê°œ`)
    
    return results
    
  } catch (error) {
    console.error('âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', error)
    throw error
  } finally {
    if (browser) {
      await browser.close()
    }
  }
}

// ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‹¤í–‰ ì‹œ
if (require.main === module) {
  crawlAllCampaigns()
    .then(() => {
      console.log('\\nğŸ‰ ëª¨ë“  í¬ë¡¤ë§ ì™„ë£Œ!')
      process.exit(0)
    })
    .catch((error) => {
      console.error('âŒ í¬ë¡¤ë§ ì‹¤íŒ¨:', error)
      process.exit(1)
    })
}

module.exports = { crawlAllCampaigns, scrapeCampaign }